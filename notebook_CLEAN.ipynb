{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC56k2CrHzyU",
    "outputId": "740ff407-f389-4e0b-c67e-7cb582ef0cdc"
   },
   "outputs": [],
   "source": [
    "# run after fresh restart\n",
    "!pip -q install --upgrade --no-cache-dir \\\n",
    "  torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q install --no-cache-dir \\\n",
    "  transformers==4.45.2 peft==0.12.0 accelerate==0.34.2 \\\n",
    "  bitsandbytes==0.43.3 triton sentencepiece \"protobuf<5\" datasets==2.21.0 \\\n",
    "  evaluate scikit-learn\n",
    "\n",
    "import torch, platform, subprocess\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available(), \"| Python:\", platform.python_version())\n",
    "try:\n",
    "    print(subprocess.check_output([\"nvidia-smi\"], text=True))\n",
    "except Exception as e:\n",
    "    print(\"No nvidia-smi:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "C4fRmWeuH2Tn",
    "outputId": "12c91acf-ac35-4a72-a95c-5cb6f8eebadb"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(list(uploaded.keys())[0])\n",
    "df = df[['title','description','requirements','fraudulent']].dropna()\n",
    "df['text'] = df['title'].astype(str) + \"\\n\" + df['description'].astype(str) + \"\\n\" + df['requirements'].astype(str)\n",
    "df['label_text'] = df['fraudulent'].map({0:\"Real\", 1:\"Fake\"})\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df[['text','label_text']], test_size=0.2, random_state=42, stratify=df['label_text']\n",
    ")\n",
    "\n",
    "# balance\n",
    "max_n = train_df['label_text'].value_counts().max()\n",
    "train_df = (train_df\n",
    "            .groupby('label_text', group_keys=False)\n",
    "            .apply(lambda x: x.sample(max_n, replace=True, random_state=42))\n",
    "            .sample(frac=1.0, random_state=42))  # shuffle\n",
    "\n",
    "# keep TEST untouched\n",
    "test_df  = test_df.sample(min(len(test_df), 400), random_state=42)\n",
    "\n",
    "# if you want to hard-cap training for speed:\n",
    "train_df = train_df.sample(min(len(train_df), 2000), random_state=42)\n",
    "\n",
    "train_df.to_json(\"train.jsonl\", orient=\"records\", lines=True)\n",
    "test_df.to_json(\"test.jsonl\",  orient=\"records\", lines=True)\n",
    "\n",
    "print(train_df['label_text'].value_counts(), \"\\n---\\n\", test_df['label_text'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "4d65c8c450e349f3bbc166091297f8b6",
      "efde27ae9af544e4a44fc9474f32688e",
      "9e354d8853f548299dfe102282ed4c81",
      "480109ff1b8f4afbafc90da9bac83850",
      "9e478cb2fd4c42a8b245a268e7639491",
      "d76af04e62fa4d7b8a66ecae529728d7",
      "9b0d01c7c42a4df48141b5085b5af474",
      "ef5a8534cdd74117b030724b242ff726",
      "9bd08fd8d8f240428898ece1ebab5a75",
      "ff8b26a19de34911bf0506d65cd77691",
      "eb6e57c29b4548bab3747fe68e99b8d5",
      "0076ff8b527b433d9dea2867f032111f",
      "0b0344efe89544838c0aa6e841f1cee1",
      "4ea56827401946d5a817c77de76f6635",
      "8a16e5e4ee744fbeaeebdea24a291a9c",
      "1692b974402f48828a5296e88450cf31",
      "750cd22d34384895bed1a745b76a7216",
      "2753ec7374394e4e9291fe606dc4d2b1",
      "300e1fdc79b7459aa2c0be41a22ce190",
      "96ed6a8e73cc4ea18d612b7181525a66",
      "d9794f4507ea416f9823fcba908ba524",
      "4c002588d0c14e6ba90fafa1962e09fe",
      "f72fbae4c17b4f0e9caad1e55a3f5811",
      "8a2caec3bb12434c878abf4ba78ea003",
      "b0e7f991175940268b17e03ff8bc8c3f",
      "80e8526b481f4be682a105d135002fb0",
      "ab8b690e7b864f0ca3f4c7134efcde43",
      "c38bddf7dd20441586f73d59f6517a0d",
      "d770613bf45045749465cd7b31d8e6b2",
      "2c46d610927c43d3b4059f41a659ee23",
      "6edb2fadf8d4487aa4574c260c3eabe4",
      "1515fbc02a9c44b58dfb214ba918fdf1",
      "7097169d6530465a9df3556412ca7b3f",
      "d7435e64f2e84471b83102764fe61140",
      "e9c5e81c930540e589380284a00bdd2e",
      "a2aa952a7f93467bbaddb6ec14900669",
      "d34fa0b0f70a4687806d5ed5271f486e",
      "0fa99a0a3dbe4f3ba573dd3481d3ebca",
      "1ec81c1bd31541cc8dd95c8a20979adc",
      "12d90e99b38344dab28dc0988128f62c",
      "eea6eab39a504ed683b01a069a749ba1",
      "fdc56096eaa54da48f8766140253f42f",
      "2b25cbf305c74a3ea05e9df68e29ffdb",
      "764b7424b1294d15918d77c608c93a58"
     ]
    },
    "id": "DQhXVLAoH5HZ",
    "outputId": "f86e4b9d-8c4d-402c-89b4-2799aa5f90d5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files={\"train\":\"train.jsonl\",\"test\":\"test.jsonl\"})\n",
    "\n",
    "def format_example(ex):\n",
    "    # keep labels as words\n",
    "    return {\"text\": f\"Decide if this job posting is Real or Fake:\\n\\n{ex['text']}\\n\\nAnswer: {ex['label_text']}\"}\n",
    "\n",
    "ds = ds.map(format_example, remove_columns=ds[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4c6b56b15a0349f998ff50e69d90359b",
      "950a3a70817e44beb137e814776c4c23",
      "dae249fe17e34f389c90ff493ad9924b",
      "2a2e1ec141f04ccc8b7dad4478d8aa9e",
      "8acff0026fa747a0aed0f927bfcf6b85",
      "b39b92390943400ea017124510533e24",
      "e7f6a36f98b9437487273c39d4b3c3fb",
      "4510d812f3cc43fa80f7c15a631f3197",
      "a20bd0201df24d84b0177f5b13697e99",
      "359aa9e0fd7a43509c5c83fd1970301f",
      "74727fb80edc43daa96b8fbfec20c910",
      "a9b93ee4bbac49d29a1fc0420d04886a",
      "c8cdb0e967c84f38add175429b88b955",
      "d49b4e83119f445fb00deb5a9f1b9e8a",
      "303b168f76b44245ae787ac542065642",
      "2ff4cfa843774ad990f1e07ec882cd25",
      "4746439a62794db881eed2e4a6ba6ddb",
      "76df089ca4394a86b4f4eb34674f557c",
      "c6ec73a1dcc349ad8f349b106e54fc2c",
      "8609a24641ff4716ab3682d3d6b8c618",
      "476aed5ee75349c5b292dd6ac2bfa3b8",
      "65a92d1698644d84b78df6e1653c271d",
      "a5d6a5a24c124b958d39c435f9f43699",
      "528e938674e94eef9775483aae0dcd72",
      "8a6f761655234fc697e7683c16c02e88",
      "7e5f997598f4425b9975997f39b27b58",
      "9429cf2d40394731b34668e018a8d762",
      "6ff725f8316c4218a92e1fde88f2304a",
      "c3eaa1b32f0d4da8b56b82f32616b872",
      "fc716a0efb7a4e4c8a02c81d26395af1",
      "4ae2b46312c34c9da6898d4eb9dc496e",
      "dffd0631fea64596a584366539a0add6",
      "3a12d5a4a0cb406d91849b56201ad231",
      "e0cae8751d4f4ef182059c2f9de34af4",
      "1256ff8ec5664d5897e9dea0bab3bcc5",
      "4a40f6e813f54be086ab8f85342131e4",
      "57daedd8226749b9b828537ad1e763d7",
      "cc99e5cba41e471b9f19cd4f7a9ddd13",
      "7deb968c632b4e4eaf2533a2b6c0e3d7",
      "2d2f90e3574b40d19013a4edb00c8f3f",
      "0167e2c0950a443bb3d45bbd57576143",
      "76f4398a3481483582d01949228816d7",
      "534fb21bff2a4f48a91aa9a4ed2ccbe3",
      "62a2b5e8c68f432f920390af1c47aca6",
      "8520ccb30f0a4aeab092e180be7af67f",
      "da0f4fc1d23b4850ba59c690a36a8a73",
      "d4a7d48577be4c69ac278800f351f81a",
      "e8edcbde48c34852be43fd216c5f3818",
      "214cbad30c584e85b7a4a1df5d34636e",
      "6319ac5bb4654257b54500290f1de60b",
      "17460e28f4574c6f99a18791f8e8e876",
      "dca8daa0e40b48729bcece7bae28fc93",
      "cabe59a510f04a11b565fddf62749c27",
      "6e3337109f204d7fa058ae3aebee064b",
      "48eb7dd2f0244d439334b657121778ec",
      "4d45fbe4e0644ab3a85c038bc9d175eb",
      "d200afb083e944b6a8c9d57369ab647d",
      "f4d9b7e348de4f03b7a1bdc35343292e",
      "1df0eee1e861425fa3e15bba65602647",
      "1280d4c5fb5a476f8a2f99ed12f64df3",
      "6bd8034aa4d24e1aa7ec54edfe35d912",
      "7f7b92d15f5b44dfb8949c78469e2304",
      "3c77d19cb19e419caba34612e1f421bc",
      "4d4b3befb3d7495aa7f42e2034df02b7",
      "5434dd694989442ab82b09826f20a8f0",
      "4be37c874e214c30a2ab697c2f21de8c",
      "c8eb6d95ff004fea801dfc20a7e5d3bb",
      "e1a65e32c3074922a1cf7017821bcb95",
      "e5c2a62b1f7343fba85c0998571a9402",
      "52aac0baa43d4bd3b7880cbbb2a57411",
      "71cec61660054a95b4500dcb820057bf",
      "a3b987c049f34a0ca2986e72cef4547a",
      "34eb3165e42d40d58501903f97c583a0",
      "38e166b1bd904f5f88c770acbce1baaa",
      "81c78c3674d94106b03d265eab7edf90",
      "d50b11f4220e43cfbfaa256ab588e30c",
      "62fc0311b7bf4fe9a22826cbfec90178",
      "a9248fe4f44242039bf417d101250586",
      "36225932901946afbb50d52dbc611d7f",
      "288f82d80c9e47cb96d361dde744c22f",
      "c193f767fa7c4d8887c1d84a23ebafe8",
      "a40b4261cd1f4d97aba802cb24bf0a53",
      "3dccc58b575546bd8695dc671cc26363",
      "0701ff88f625428a8a0bfec889b7fc5a",
      "dc6eb4f15f9f4927bbcfa57ced0494cc",
      "79d97a077b344d99955a87efef88d1d6",
      "606fb58b4700416289fed54a9d57d6ab",
      "a4293d07a0994e2786e5b18448484eb5",
      "19653e3cf0084920a584e236ce0b3781",
      "9bf25bfe3df34ad8a74d003e6583feb6",
      "b610c80e36094ff7810cb9d9fc80e238",
      "f03f4e33c7d949d4944687445678b850",
      "75b3d4a89e274e48aedf0c7384f3b993",
      "641d7ee22d4b4bd0ac87650854a9ee1b",
      "ccfa4b57d9ff4d519452ff28549999ee",
      "34bf00b02c774f8dbfdc157108f0b55d",
      "da3517fc118449a680ef102276ac55b3",
      "59a08b2a8f7f42deb4206a464120f1d9",
      "13644d6c12d24c2ebbade8d22c27c480",
      "d328f7bf03a94ca48cb80b0bd27a4804",
      "349f3a77f35543558e660f4ad89e46f6",
      "3864fe764c6f4005af2a4bda017c6563",
      "4a0d70bfbb7e4f3dab0ac11635869b31",
      "50516e609437465c9afe1698439d8b1c",
      "b6ce918a5f6d4cbc933919ac94964cbe",
      "986ad460eb0d4fb1a0621e9e5e04d7aa",
      "59f7812e8d4741579f01e201bfdbb740",
      "e7b4f344bc444fb485174f5881078a31",
      "bb527b08d15541058580edba51345b81",
      "d66fab435db74a1bbb15b0555c9a1746",
      "9c8f1c8119b542b2b0707fa2584e2fa3",
      "aa36bfbe566d418a978b21c1d3ce3b87",
      "8428180bed994dbb80070a43dc32cd38",
      "b086f801f07e4952907b102d1285cb6c",
      "6129215116ba4c55bb778e7d7c43cfd8",
      "0887f4bc8c4f4416a7bf1e7d7960e705",
      "bc63e3f909c749e6ac6236b5f223a043",
      "7d2a75bda3e64c19bbd4c390a6a04c94",
      "ef555d0769914862a6e80764efb17469",
      "df3cb5a163f846649bf2efe7991e7533",
      "286363f82c61412f9f6308671b0e5a57",
      "ca75ad7ad1a745839dc781b63340e516",
      "40ac49d6f10d4434a2dd4363eb54fb77",
      "f7ad69e98cc74dcc94c269692cd07d0f",
      "ddbbb52d687144f2be3b0af37550f9a4",
      "289f410983a84b058271fb9d8c448688",
      "79884691ce7b4e53b10658f1141be660",
      "4d03b4c58373492883d332c39ec1619c",
      "0c24f410e0a341439d7af42ee3c053e0",
      "ae2b70ad253a4e539834e4947ff864d7",
      "07b26faf9e3149e596163f8c154b1724",
      "49284e5709c3447085e23a3f01ce0c2f",
      "117ae837608a4b9496cc52fed2673fc3",
      "fe00fdde549343d88269910c2ceb2952",
      "73dfc139b52d4a96a999e185840692b4",
      "947fdfcfba5d4b849048805ec8998eb2",
      "c52607d9567c45c394f86442dbce1705",
      "8c7e28fb346045fe86d69af7abfcae95",
      "4cb4eebbc33f46328ff7e73445c87ee8",
      "2203b6516ff64430b17e17908012dc0b",
      "cbefd0d2b4684f8ba4fbfc2bf7c1e7a7",
      "97fbe3fd584e42fda11b956f7d112230",
      "b0118c3343914db1b2b8d83ce88ac3fc",
      "00e9def2097647bb91117f4905226c23",
      "30c0387d160541a8b9cb27eb49bba063",
      "ab5ace4b5a404b53843dc0266b89781a",
      "e704cfe8dba2487aa6ff2d7d94508343",
      "04ae66614ee14f9bbabc0ad40dc281ff",
      "009bd274fc1a44428848335be5b431d9",
      "4fdba29f64ae44d18b7903cafeec0c7a",
      "5ff931e2e1bb48fd85c470bc1abfc52a",
      "7179c0d4273e48e4996ef8382438bb73",
      "5a318b2020204ff4bf66f0730baaf733",
      "3eae6cd0886e47bfba65832acedde10a"
     ]
    },
    "id": "3e2xiz_kH9-L",
    "outputId": "ba395f16-3ef4-48e0-bb87-69a77cc0384d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n",
    "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
    "tok.padding_side = \"right\"\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# single load\n",
    "max_memory = {0: \"13GiB\", \"cpu\": \"24GiB\"}\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb,\n",
    "    device_map=\"auto\",\n",
    "    max_memory=max_memory,\n",
    "    torch_dtype=torch.float16,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora = LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 128 usually enough\n",
    "MAXLEN = 128\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=MAXLEN, padding=\"max_length\")\n",
    "\n",
    "tok_ds = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Collator:\n",
    "    pad_token_id: int\n",
    "    def __call__(self, feats):\n",
    "        input_ids = torch.tensor([f[\"input_ids\"] for f in feats], dtype=torch.long)\n",
    "        attention_mask = torch.tensor([f[\"attention_mask\"] for f in feats], dtype=torch.long)\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "collator = Collator(pad_token_id=tok.pad_token_id)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./mistral-qlora-fakejobs\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,   # ← effectively batch=4\n",
    "    max_steps=160,                   # you can raise to 400 if need\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=20,\n",
    "    fp16=True,\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=[],\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    gradient_checkpointing=True,\n",
    "    eval_strategy=\"no\",              # ← avoids mid-train eval memory spikes\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    data_collator=collator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"mistral_finetuned_lora_t4\")\n",
    "tok.save_pretrained(\"mistral_finetuned_lora_t4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOQyl4T2H-qM",
    "outputId": "1e04b86f-5f55-4e19-c974-77c336cbfe29"
   },
   "outputs": [],
   "source": [
    "# calibration (clamped bias + class counts) (BASELINE)\n",
    "import json, numpy as np, torch, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "model.eval()\n",
    "MAXLEN = 128\n",
    "\n",
    "def first_id_for(text):\n",
    "    return tok(text, add_special_tokens=False).input_ids[0]\n",
    "\n",
    "rid = first_id_for(\" Real\"); fid = first_id_for(\" Fake\"); uid = first_id_for(\" Uncertain\")\n",
    "label_ids = torch.tensor([rid, fid, uid], device=device)\n",
    "\n",
    "def score_texts(texts, batch=8):\n",
    "    outs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch):\n",
    "            enc = tok(texts[i:i+batch], return_tensors=\"pt\",\n",
    "                      truncation=True, max_length=MAXLEN, padding=True).to(device)\n",
    "            logits = model(**enc, use_cache=False).logits[:, -1, :]\n",
    "            outs.append(logits[:, label_ids])\n",
    "    return torch.cat(outs, dim=0)\n",
    "\n",
    "def decide(logits, bias_fake=0.0, p_uncertain=0.50, margin=0.10):\n",
    "    l = logits.clone().float()\n",
    "    l[:, 1] += bias_fake\n",
    "    probs = torch.softmax(l, dim=-1)\n",
    "    top_p, top_i = probs.max(dim=-1)\n",
    "    second_p = probs.topk(2, dim=-1).values[:, 1]\n",
    "    out = []\n",
    "    for i in range(l.size(0)):\n",
    "        if (top_p[i].item() < p_uncertain) or ((top_p[i]-second_p[i]).item() < margin):\n",
    "            out.append(\"Uncertain\")\n",
    "        else:\n",
    "            out.append([\"Real\",\"Fake\",\"Uncertain\"][top_i[i].item()])\n",
    "    return out\n",
    "\n",
    "def metrics_for(preds, gold, tiebreak=\"Real\"):\n",
    "    p2 = [p if p in (\"Real\",\"Fake\") else tiebreak for p in preds]\n",
    "    acc = accuracy_score(gold, p2)\n",
    "    f1w = f1_score(gold, p2, average=\"weighted\")\n",
    "    return acc, f1w\n",
    "\n",
    "# build\n",
    "prompts, gold = [], []\n",
    "with open(\"test.jsonl\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        gold.append(ex[\"label_text\"])\n",
    "        prompts.append(f\"Decide if this job posting is Real or Fake.\\n\\n{ex['text']}\\n\\nAnswer:\")\n",
    "\n",
    "prom_calib, prom_eval, y_calib, y_eval = train_test_split(\n",
    "    prompts, gold, test_size=0.8, random_state=42, stratify=gold\n",
    ")\n",
    "logits_calib = score_texts(prom_calib)\n",
    "logits_eval  = score_texts(prom_eval)\n",
    "\n",
    "# search moderate bias\n",
    "best = (-1.0, 0.0)\n",
    "for b in np.linspace(-0.8, +0.8, 33):  # narrower range avoids overcorrection\n",
    "    preds_c = decide(logits_calib, bias_fake=b, p_uncertain=0.50, margin=0.10)\n",
    "    p2 = [p if p in (\"Real\",\"Fake\") else \"Real\" for p in preds_c]\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1f = f1_score(y_calib, p2, pos_label=\"Fake\")\n",
    "    if f1f > best[0]:\n",
    "        best = (f1f, b)\n",
    "\n",
    "best_bias = float(best[1])\n",
    "print(f\"Chosen Fake-bias: {best_bias:+.2f}\")\n",
    "\n",
    "preds = decide(logits_eval, bias_fake=best_bias, p_uncertain=0.50, margin=0.10)\n",
    "acc, f1w = metrics_for(preds, y_eval)\n",
    "print(f\"CALIBRATED — Acc (forced 2-label): {acc:.3f}  F1(weighted): {f1w:.3f}\")\n",
    "\n",
    "labels2 = [\"Real\",\"Fake\"]\n",
    "preds2 = [p if p in labels2 else \"Real\" for p in preds]\n",
    "cm = pd.DataFrame(confusion_matrix(y_eval, preds2, labels=labels2),\n",
    "                  index=labels2, columns=[f\"Pred {l}\" for l in labels2])\n",
    "print(cm)\n",
    "\n",
    "# show class counts\n",
    "from collections import Counter\n",
    "print(\"Pred counts:\", Counter(preds))\n",
    "u_rate = sum(1 for p in preds if p==\"Uncertain\") / len(preds)\n",
    "print(f\"Uncertain rate: {u_rate:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN_49T76IDMU",
    "outputId": "9a19ea90-1be9-4113-f343-d2ec29fb7941"
   },
   "outputs": [],
   "source": [
    "import gc, torch, psutil, os\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"RAM used:\", psutil.virtual_memory().percent, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzwNIFmI5emn",
    "outputId": "3b6d0d2d-4e40-4d44-d014-5027317a57a6"
   },
   "outputs": [],
   "source": [
    "# calibration (logistic calibrator + Uncertain by confidence) (TUNED)\n",
    "import json, numpy as np, torch, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "model.eval()\n",
    "MAXLEN = 128  # keep in sync with training\n",
    "\n",
    "def token_set_for(label_word: str):\n",
    "    ids = set()\n",
    "    for variant in [label_word, f\" {label_word}\"]:\n",
    "        toks = tok(variant, add_special_tokens=False).input_ids\n",
    "        if toks: ids.add(toks[0])\n",
    "    return sorted(ids)\n",
    "\n",
    "real_ids = token_set_for(\"Real\")\n",
    "fake_ids = token_set_for(\"Fake\")\n",
    "unc_ids  = token_set_for(\"Uncertain\")\n",
    "\n",
    "def slice_label_logits(next_logits):  # next_logits: [B,V]\n",
    "    def max_col(ids):\n",
    "        cols = [next_logits[:, i] for i in ids if i < next_logits.size(1)]\n",
    "        if not cols:\n",
    "            return torch.full((next_logits.size(0),), -1e9, device=next_logits.device)\n",
    "        return torch.stack(cols, dim=1).max(dim=1).values\n",
    "    return torch.stack([max_col(real_ids), max_col(fake_ids), max_col(unc_ids)], dim=1)  # [B,3]\n",
    "\n",
    "def score_texts(texts, batch=8):\n",
    "    outs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch):\n",
    "            enc = tok(texts[i:i+batch], return_tensors=\"pt\",\n",
    "                      truncation=True, max_length=MAXLEN, padding=True).to(device)\n",
    "            next_logits = model(**enc, use_cache=False).logits[:, -1, :]\n",
    "            outs.append(slice_label_logits(next_logits))\n",
    "    return torch.cat(outs, dim=0)  # [N,3]\n",
    "\n",
    "# build prompts\n",
    "prompts, gold = [], []\n",
    "with open(\"test.jsonl\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        gold.append(ex[\"label_text\"])\n",
    "        prompts.append(f\"Decide if this job posting is Real or Fake.\\n\\n{ex['text']}\\n\\nAnswer:\")\n",
    "\n",
    "# 30% calibration / 70% evaluation\n",
    "prom_calib, prom_eval, y_calib, y_eval = train_test_split(\n",
    "    prompts, gold, test_size=0.7, random_state=42, stratify=gold\n",
    ")\n",
    "\n",
    "logits_calib = score_texts(prom_calib)  # [C,3]\n",
    "logits_eval  = score_texts(prom_eval)   # [E,3]\n",
    "\n",
    "# features for a tiny meta-classifier (no GPU strain)\n",
    "def feats_from_logits(L):  # L: [N,3] -> features [lR, lF, lU, gap(F-R)]\n",
    "    lR, lF, lU = L[:,0].cpu().numpy(), L[:,1].cpu().numpy(), L[:,2].cpu().numpy()\n",
    "    gap = (L[:,1] - L[:,0]).cpu().numpy()\n",
    "    return np.stack([lR, lF, lU, gap], axis=1)\n",
    "\n",
    "Xc = feats_from_logits(logits_calib)\n",
    "Xe = feats_from_logits(logits_eval)\n",
    "yc = np.array([1 if y==\"Fake\" else 0 for y in y_calib])  # 1=Fake, 0=Real\n",
    "\n",
    "clf = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\", max_iter=1000)\n",
    "clf.fit(Xc, yc)\n",
    "\n",
    "# predict fake\n",
    "fake_prob = clf.predict_proba(Xe)[:,1]\n",
    "\n",
    "# choose thresholds through a sweep to maximize weighted F1 on calibration\n",
    "best = {\"f1w\": -1, \"tau\": 0.50, \"conf_t\": 0.55}\n",
    "from sklearn.metrics import f1_score\n",
    "for tau in np.linspace(0.40, 0.60, 21):\n",
    "    for conf_t in np.linspace(0.50, 0.70, 21):\n",
    "        p_cal = clf.predict_proba(Xc)[:,1]\n",
    "        preds_tmp = []\n",
    "        for p in p_cal:\n",
    "            if max(p, 1-p) < conf_t:\n",
    "                preds_tmp.append(\"Uncertain\")\n",
    "            else:\n",
    "                preds_tmp.append(\"Fake\" if p >= tau else \"Real\")\n",
    "        forced = [(\"Fake\" if p==\"Fake\" else \"Real\") for p in preds_tmp]\n",
    "        f1w = f1_score(y_calib, forced, average=\"weighted\", pos_label=\"Fake\")\n",
    "        if f1w > best[\"f1w\"]:\n",
    "            best = {\"f1w\": f1w, \"tau\": float(tau), \"conf_t\": float(conf_t)}\n",
    "\n",
    "tau, conf_t = best[\"tau\"], best[\"conf_t\"]\n",
    "print(f\"Chosen thresholds → tau={tau:.2f} (Fake cut), conf_t={conf_t:.2f} (Uncertain)\")\n",
    "\n",
    "# apply on eval\n",
    "preds = []\n",
    "for p in fake_prob:\n",
    "    if max(p, 1-p) < conf_t:\n",
    "        preds.append(\"Uncertain\")\n",
    "    else:\n",
    "        preds.append(\"Fake\" if p >= tau else \"Real\")\n",
    "\n",
    "def metrics_for(preds, gold, tiebreak=\"Real\"):\n",
    "    p2 = [p if p in (\"Real\",\"Fake\") else tiebreak for p in preds]\n",
    "    acc = accuracy_score(gold, p2)\n",
    "    f1w = f1_score(gold, p2, average=\"weighted\")\n",
    "    return acc, f1w\n",
    "\n",
    "acc, f1w = metrics_for(preds, y_eval)\n",
    "print(f\"CALIBRATED — Acc (forced 2-label): {acc:.3f}  F1(weighted): {f1w:.3f}\")\n",
    "\n",
    "labels2 = [\"Real\",\"Fake\"]\n",
    "p2 = [p if p in labels2 else \"Real\" for p in preds]\n",
    "cm = pd.DataFrame(confusion_matrix(y_eval, p2, labels=labels2),\n",
    "                  index=labels2, columns=[f\"Pred {l}\" for l in labels2])\n",
    "print(cm)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Pred counts:\", Counter(preds))\n",
    "u_rate = sum(1 for p in preds if p==\"Uncertain\") / len(preds)\n",
    "print(f\"Uncertain rate: {u_rate:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MT7YPSaQ5ftH",
    "outputId": "447c1ee6-c511-4acf-fba5-39e99104453d"
   },
   "outputs": [],
   "source": [
    "# reasons for fakes\n",
    "import re, json, html\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def norm_text(t: str) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        t = str(t)\n",
    "    t = html.unescape(t)\n",
    "    t = re.sub(r\"<[^>]+>\", \" \", t)           # strip HTML tags\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    # common obfuscations\n",
    "    t = re.sub(r\"\\b(?:\\(|\\[)?at(?:\\)|\\])?\\b\", \"@\", t, flags=re.I)\n",
    "    t = re.sub(r\"\\b(?:\\(|\\[)?dot(?:\\)|\\])?\\b\", \".\", t, flags=re.I)\n",
    "    t = re.sub(r\"g\\s*m\\s*a\\s*i\\s*l\", \"gmail\", t, flags=re.I)\n",
    "    t = re.sub(r\"y\\s*a\\s*h\\s*o\\s*o\", \"yahoo\", t, flags=re.I)\n",
    "    t = re.sub(r\"o\\s*u\\s*t\\s*l\\s*o\\s*o\\s*k\", \"outlook\", t, flags=re.I)\n",
    "    return t\n",
    "\n",
    "# regexes & helpers\n",
    "EMAIL    = re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.(?:com|net|org|io|co|edu)\\b\", re.I)\n",
    "FREE_DOM = re.compile(r\"@(gmail|yahoo|outlook|hotmail|protonmail)\\.\", re.I)\n",
    "PHONE    = re.compile(r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\\b\")\n",
    "URL      = re.compile(r\"https?://\\S+\")\n",
    "SHORTEN  = re.compile(r\"(bit\\.ly|tinyurl\\.com|linktr\\.ee|t\\.co|is\\.gd|goo\\.gl|forms\\.gle)\", re.I)\n",
    "\n",
    "CHAT_APPS = re.compile(r\"\\b(telegram|whatsapp|signal|skype|wechat|discord)\\b\", re.I)\n",
    "TEXT_ONLY = re.compile(r\"\\b(interview|onboarding|orientation)\\b.*\\b(chat|text|telegram|whatsapp|signal|discord)\\b\", re.I)\n",
    "\n",
    "PAY_APPS  = re.compile(r\"\\b(zelle|cash\\s*app|cashapp|venmo|apple\\s*pay|google\\s*pay|moneygram|western\\s*union)\\b\", re.I)\n",
    "CRYPTO    = re.compile(r\"\\b(crypto|bitcoin|btc|usdt|wallet|metamask)\\b\", re.I)\n",
    "FEE_LANG  = re.compile(r\"\\b(upfront|processing|training|registration|equipment)\\s+fee\\b\", re.I)\n",
    "DEPOSIT   = re.compile(r\"\\b(cash(?:\\s|-)?ier'?s?\\s*check|mobile\\s*deposit|check\\s*deposit)\\b\", re.I)\n",
    "RESHIP    = re.compile(r\"\\b(reship|package\\s*handler|parcel\\s*forward|warehouse\\s*at\\s*home|logistics\\s*agent)\\b\", re.I)\n",
    "\n",
    "GOOGLE_FORMS = re.compile(r\"\\b(forms\\.gle|docs\\.google\\.com/forms)\\b\", re.I)\n",
    "GOOGLE_DRIVE = re.compile(r\"\\b(drive\\.google\\.com)\\b\", re.I)\n",
    "CLICKY       = re.compile(r\"\\b(click\\s+(?:the\\s+)?link|apply\\s+via\\s+link|fill\\s+the\\s+form|complete\\s+the\\s+form)\\b\", re.I)\n",
    "\n",
    "TOO_GOOD  = re.compile(r\"\\b(no\\s*experience|immediate|urgent|quick\\s*money|daily\\s*pay|weekly\\s*pay|work\\s*from\\s*home|remote\\s*only)\\b\", re.I)\n",
    "NO_INTERV = re.compile(r\"\\b(no\\s*interview|required\\s*immediately)\\b\", re.I)\n",
    "VISA      = re.compile(r\"\\bvisa\\s*sponsor(ship)?\\b\", re.I)\n",
    "\n",
    "PAY_HIGH  = re.compile(r\"\\$\\s*([5-9]\\d|[1-9]\\d{2,})\\s*/\\s*(hr|hour|week|day)\", re.I)\n",
    "\n",
    "# common scam role names\n",
    "ROLE_BAIT = re.compile(r\"\\b(data\\s*entry|typist|repack|shipping\\s*clerk|personal\\s*assistant|virtual\\s*assistant|payroll\\s*assistant)\\b\", re.I)\n",
    "\n",
    "def basic_features(t: str):\n",
    "    \"\"\"Return small feature dict for concrete cues.\"\"\"\n",
    "    n_chars = len(t)\n",
    "    words   = re.findall(r\"\\b\\w+\\b\", t)\n",
    "    n_words = len(words)\n",
    "    caps_tokens = [w for w in words if sum(c.isupper() for c in w) >= 3 and sum(c.isalpha() for c in w) >= 3]\n",
    "    caps_ratio  = len(caps_tokens) / max(1, n_words)\n",
    "\n",
    "    emails = EMAIL.findall(t)\n",
    "    free_emails = [e for e in emails if FREE_DOM.search(e)]\n",
    "    urls = URL.findall(t)\n",
    "    short_urls = [u for u in urls if SHORTEN.search(u)]\n",
    "    phones = PHONE.findall(t)\n",
    "\n",
    "    return {\n",
    "        \"n_chars\": n_chars, \"n_words\": n_words,\n",
    "        \"caps_ratio\": caps_ratio,\n",
    "        \"n_emails\": len(emails), \"n_free_emails\": len(free_emails),\n",
    "        \"n_urls\": len(urls), \"n_short\": len(short_urls),\n",
    "        \"n_phones\": len(phones),\n",
    "    }\n",
    "\n",
    "def feature_reasons(t: str, max_cues=3):\n",
    "    cues = []\n",
    "    T = norm_text(t)\n",
    "    Tl = T.lower()\n",
    "\n",
    "    # pattern hits\n",
    "    if TEXT_ONLY.search(T):     cues.append(\"interview/onboarding over text/chat app\")\n",
    "    if CHAT_APPS.search(T):     cues.append(\"redirects to chat app for hiring\")\n",
    "    if FEE_LANG.search(T):      cues.append(\"mentions upfront/processing/training/equipment fee\")\n",
    "    if PAY_APPS.search(T):      cues.append(\"requests payment via Zelle/CashApp/Venmo/etc.\")\n",
    "    if CRYPTO.search(T):        cues.append(\"mentions crypto payments/wallet\")\n",
    "    if DEPOSIT.search(T):       cues.append(\"check-deposit / cashier’s check scheme\")\n",
    "    if RESHIP.search(T):        cues.append(\"reshipping / at-home logistics\")\n",
    "    if GOOGLE_FORMS.search(T):  cues.append(\"collects info via Google Forms\")\n",
    "    if GOOGLE_DRIVE.search(T):  cues.append(\"shares Google Drive link for onboarding\")\n",
    "    if CLICKY.search(T):        cues.append(\"pressures to click external link/form\")\n",
    "    if NO_INTERV.search(T):     cues.append(\"claims no interview / immediate start\")\n",
    "    if TOO_GOOD.search(T):      cues.append(\"too-good-to-be-true pitch (quick money/no experience/remote-only)\")\n",
    "    if VISA.search(T):          cues.append(\"vague visa sponsorship claim\")\n",
    "    if ROLE_BAIT.search(T):     cues.append(\"role matches common scam bait (data entry/personal assistant/etc.)\")\n",
    "    if PAY_HIGH.search(T):      cues.append(\"unusually high pay claim\")\n",
    "\n",
    "    # feeature counts\n",
    "    feats = basic_features(T)\n",
    "    if feats[\"n_free_emails\"] > 0:\n",
    "        cues.append(\"uses free email domain for hiring\")\n",
    "    elif feats[\"n_emails\"] > 0:\n",
    "        # any email but not company domain is still suspicious if no company is named\n",
    "        cues.append(\"direct email contact instead of company domain portal\")\n",
    "\n",
    "    if feats[\"n_phones\"] > 0:\n",
    "        cues.append(\"phone/text contact provided\")\n",
    "\n",
    "    if feats[\"n_urls\"] >= 3:\n",
    "        cues.append(f\"contains {feats['n_urls']} links (possible off-platform funnel)\")\n",
    "    elif feats[\"n_urls\"] >= 1 and feats[\"n_short\"] >= 1:\n",
    "        cues.append(\"uses URL shortener (bit.ly/tinyurl/etc.)\")\n",
    "\n",
    "    if feats[\"caps_ratio\"] > 0.10:\n",
    "        cues.append(\"excessive ALL-CAPS wording\")\n",
    "    if feats[\"n_words\"] < 60:\n",
    "        cues.append(\"very short description, lacks detail\")\n",
    "    elif feats[\"n_words\"] > 800:\n",
    "        cues.append(\"unusually long description (padding/boilerplate)\")\n",
    "\n",
    "    # remove duplicates\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for c in cues:\n",
    "        if c and c not in seen:\n",
    "            out.append(c)\n",
    "            seen.add(c)\n",
    "        if len(out) >= max_cues:\n",
    "            break\n",
    "\n",
    "    if not out:\n",
    "        out = [\"signals unclear\"]\n",
    "    return out\n",
    "\n",
    "# reasons for fake\n",
    "raw_eval_texts = [p.split(\"Real or Fake.\\n\\n\",1)[1].rsplit(\"\\n\\nAnswer:\",1)[0] for p in prom_eval]\n",
    "\n",
    "fake_rows = []\n",
    "for i, label in enumerate(preds):\n",
    "    if label == \"Fake\":\n",
    "        reasons = feature_reasons(raw_eval_texts[i], max_cues=3)\n",
    "        fake_rows.append({\"idx\": i, \"reasons\": reasons})\n",
    "\n",
    "print(f\"Explained {len(fake_rows)} Fake items. Sample:\")\n",
    "print(fake_rows[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "ViDisAzGZvne",
    "outputId": "05f2c7d4-aa10-43e0-ee9e-0bcd079f1869"
   },
   "outputs": [],
   "source": [
    "# Clean a notebook so GitHub can render it (removes metadata.widgets + clears outputs)\n",
    "import os, re, html, json, glob, time\n",
    "import nbformat as nbf\n",
    "\n",
    "def pick_notebook():\n",
    "    # 1) try COLAB_NOTEBOOK_PATH\n",
    "    nb_path = os.environ.get(\"COLAB_NOTEBOOK_PATH\")\n",
    "    if nb_path and os.path.isfile(nb_path):\n",
    "        return nb_path\n",
    "    # 2) try newest .ipynb in /content\n",
    "    cands = sorted(glob.glob(\"/content/*.ipynb\"), key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "    if cands:\n",
    "        print(\"Auto-selected most recent .ipynb:\", os.path.basename(cands[0]))\n",
    "        return cands[0]\n",
    "    # 3) ask you to upload a notebook\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"No .ipynb found in /content — please select your notebook file to clean…\")\n",
    "        uploaded = files.upload()  # opens picker\n",
    "        if uploaded:\n",
    "            fname = list(uploaded.keys())[0]\n",
    "            return \"/content/\" + fname\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    raise SystemExit(\"No notebook file found. Upload a .ipynb and re-run this cell.\")\n",
    "\n",
    "nb_path = pick_notebook()\n",
    "print(\"Cleaning:\", nb_path)\n",
    "\n",
    "nb = nbf.read(nb_path, as_version=4)\n",
    "\n",
    "# Remove notebook-level widgets metadata\n",
    "nb.metadata.pop(\"widgets\", None)\n",
    "\n",
    "# Clean per-cell outputs + any cell-level widget metadata\n",
    "for cell in nb.cells:\n",
    "    if hasattr(cell, \"metadata\"):\n",
    "        cell.metadata.pop(\"widgets\", None)\n",
    "    if \"outputs\" in cell:\n",
    "        cell[\"outputs\"] = []\n",
    "    if \"execution_count\" in cell:\n",
    "        cell[\"execution_count\"] = None\n",
    "\n",
    "# Write cleaned copy\n",
    "root, ext = os.path.splitext(nb_path)\n",
    "clean_path = root + \"_CLEAN.ipynb\"\n",
    "nbf.write(nb, clean_path)\n",
    "print(\"Wrote:\", clean_path)\n",
    "\n",
    "# (Optional) also export HTML for easy viewing\n",
    "try:\n",
    "    import subprocess, sys\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"nbconvert==7.16.6\"], check=True)\n",
    "    subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"html\", \"--no-input\", \"--no-prompt\", clean_path], check=True)\n",
    "    print(\"HTML written:\", clean_path.replace(\".ipynb\", \".html\"))\n",
    "except Exception as e:\n",
    "    print(\"HTML export skipped:\", e)\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1) In the left Files pane, right-click the *_CLEAN.ipynb and Download it.\")\n",
    "print(\"2) On GitHub → your repo → Add file → Upload files → drop the *_CLEAN.ipynb (and optional .html).\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
